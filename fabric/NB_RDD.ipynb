{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "microsoft": {
   "language": "python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   },
   "host": {}
  },
  "widgets": {},
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "synapse_pyspark",
   "display_name": "Synapse PySpark"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "save_output": true,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "enableDebugMode": false,
    "conf": {}
   }
  },
  "notebook_environment": {},
  "synapse_widget": {
   "version": "0.1",
   "state": {}
  },
  "trident": {
   "lakehouse": {
    "default_lakehouse": "be6aaade-86ef-42f1-8737-a6f25e807137",
    "known_lakehouses": [
     {
      "id": "be6aaade-86ef-42f1-8737-a6f25e807137"
     }
    ],
    "default_lakehouse_name": "Bronze",
    "default_lakehouse_workspace_id": "02ce6c99-9dde-4918-9a38-d95b612d774e"
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "from pyspark.sql.functions import col, avg, max, when\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, avg, when\n",
    "\n",
    "% TODO parametrize your delta table e.g., name_of_your_lakehouse.delta_table_name\n",
    "% true_big_table is based on yellow_tripdata_2015-01.csv\n",
    "\n",
    "df = spark.sql(\"SELECT * FROM Bronze.true_big_table\")\n",
    "df.count()\n",
    "# 815,935,104 = 815 mln of rows\n",
    "print(\"Step 1\")\n",
    "# Define the segments for trip_distance\n",
    "segments = [0, 5, 10, 15, 20, 25]\n",
    "\n",
    "# Add a new column for segment based on trip_distance\n",
    "df_with_segment = df.withColumn(\"distance_segment\", when(\n",
    "    col(\"trip_distance\").isNull(), None\n",
    ").otherwise(\n",
    "    when(col(\"trip_distance\") <= segments[0], \"<= \" + str(segments[0]))\n",
    "    .when(col(\"trip_distance\") <= segments[1], str(segments[0]+0.01) + \" - \" + str(segments[1]))\n",
    "    .when(col(\"trip_distance\") <= segments[2], str(segments[1]+0.01) + \" - \" + str(segments[2]))\n",
    "    .when(col(\"trip_distance\") <= segments[3], str(segments[2]+0.01) + \" - \" + str(segments[3]))\n",
    "    .when(col(\"trip_distance\") <= segments[4], str(segments[3]+0.01) + \" - \" + str(segments[4]))\n",
    "    .otherwise(\">= \" + str(segments[4]+0.01))\n",
    "))\n",
    "print(\"Step 2\")\n",
    "# Calculate average fare_amount and tip_amount per segment\n",
    "avg_amounts_by_segment = df_with_segment.groupBy(\"distance_segment\").agg(\n",
    "    avg(\"fare_amount\").alias(\"avg_fare_amount\"),\n",
    "    avg(\"tip_amount\").alias(\"avg_tip_amount\")\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "avg_amounts_by_segment.count()\n",
    "\n",
    "# Define the segments for trip_distance\n",
    "segments = [0, 5, 10, 15, 20, 25]\n",
    "print(\"Step 3\")\n",
    "# Add a new column for segment based on trip_distance\n",
    "df_with_segment = df.withColumn(\"distance_segment\", when(\n",
    "    col(\"trip_distance\").isNull(), None\n",
    ").otherwise(\n",
    "    when(col(\"trip_distance\") <= segments[0], \"<= \" + str(segments[0]))\n",
    "    .when(col(\"trip_distance\") <= segments[1], str(segments[0]+0.01) + \" - \" + str(segments[1]))\n",
    "    .when(col(\"trip_distance\") <= segments[2], str(segments[1]+0.01) + \" - \" + str(segments[2]))\n",
    "    .when(col(\"trip_distance\") <= segments[3], str(segments[2]+0.01) + \" - \" + str(segments[3]))\n",
    "    .when(col(\"trip_distance\") <= segments[4], str(segments[3]+0.01) + \" - \" + str(segments[4]))\n",
    "    .otherwise(\">= \" + str(segments[4]+0.01))\n",
    "))\n",
    "\n",
    "# Calculate average fare_amount, tip_amount, and maximum values per segment\n",
    "avg_amounts_by_segment = df_with_segment.groupBy(\"distance_segment\").agg(\n",
    "    avg(\"fare_amount\").alias(\"avg_fare_amount\"),\n",
    "    avg(\"tip_amount\").alias(\"avg_tip_amount\"),\n",
    "    max(\"fare_amount\").alias(\"max_fare_amount\"),\n",
    "    max(\"tip_amount\").alias(\"max_tip_amount\")\n",
    ")\n",
    "print(\"Step 4\")\n",
    "# Order the resulting DataFrame by the first column\n",
    "ordered_avg_amounts_by_segment = avg_amounts_by_segment.withColumn(\"distance_segment\",\n",
    "    F.when(col(\"distance_segment\").startswith(\"<\"), F.split(col(\"distance_segment\"), \" \")[1])\n",
    "    .otherwise(F.split(col(\"distance_segment\"), \" - \")[0])\n",
    ").orderBy(col(\"distance_segment\").cast(\"float\"))\n",
    "\n",
    "# Display the result\n",
    "ordered_avg_amounts_by_segment.count()\n",
    "\n",
    "print(\"Step 5\")\n",
    "\n",
    "# Compute the average trip distance by VendorID\n",
    "avg_distance = df.groupBy('VendorID').avg('trip_distance')\n",
    "avg_distance.count()\n",
    "\n",
    "# Identify the top 10 locations with the highest average tip amount\n",
    "top_locations = df.groupBy('pickup_longitude', 'pickup_latitude').avg('tip_amount')\n",
    "top_locations = top_locations.sort('avg(tip_amount)', ascending=False).limit(10)\n",
    "top_locations.count()\n",
    "\n",
    "print(\"Step 6\")\n",
    "# Compute the total revenue by payment type\n",
    "total_revenue = df.groupBy('payment_type').sum('total_amount')\n",
    "total_revenue.count()\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "session_id": "bb9d753a-0434-4290-b0d5-543c1c0f738c",
       "statement_id": 5,
       "state": "finished",
       "livy_statement_state": "cancelled",
       "queued_time": "2023-07-26T18:57:37.3791403Z",
       "session_start_time": null,
       "execution_start_time": "2023-07-26T18:57:37.6355365Z",
       "execution_finish_time": "2023-07-26T18:57:50.8406913Z",
       "spark_jobs": {
        "numbers": {
         "FAILED": 1,
         "RUNNING": 0,
         "SUCCEEDED": 0,
         "UNKNOWN": 0
        },
        "jobs": [
         {
          "displayName": "toString at String.java:2994",
          "dataWritten": 0,
          "dataRead": 0,
          "rowCount": 0,
          "usageDescription": "",
          "jobId": 8,
          "name": "toString at String.java:2994",
          "description": "Delta: Job group for statement 5:\nimport time\nfrom pyspark.sql.functions import col, avg, max, when\nfrom pyspark.sql.window import Window\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import col, avg, when\n\n\nfor i in range(5):\n    print(i)\n    df = spark.sql(\"SELECT * FROM Bronze.true_big_table\")\n    df.count()\n    # 815,935,104 = 815 mln of rows\n    print(\"Step 1\")\n    # Define the segments for trip_distance\n    segments = [0, 5, 10, 15, 20, 25]\n\n    # Add a new column for segment based on trip_distance\n    df_with_segment = df.withColumn(\"distance_segment\", when(\n        col(\"trip_distance\").isNull(), None\n    ).otherwise(\n        when(col(\"trip_distance\") <= segments[0], \"<= \" + str(segments[0]))\n        .when(col(\"trip_distance\") <= segments[1], str(segments[0]+0.01) + \" - \" + str(segments[1]))\n        .when(col(\"trip_distance\") <= segments[2], str(segments[1]+0.01) + \" - \" + str(segments[2]))\n        .when(col(\"trip_distance\") <= segments[3], str(segments[2]+0.01) + \" - \" + str(segments[3]))\n        .when(col(\"trip_di...: Compute snapshot for version: 6",
          "submissionTime": "2023-07-26T18:57:48.944GMT",
          "completionTime": "2023-07-26T18:57:49.048GMT",
          "stageIds": [
           12
          ],
          "jobGroup": "5",
          "status": "FAILED",
          "numTasks": 7,
          "numActiveTasks": 0,
          "numCompletedTasks": 0,
          "numSkippedTasks": 0,
          "numFailedTasks": 0,
          "numKilledTasks": 7,
          "numCompletedIndices": 0,
          "numActiveStages": 0,
          "numCompletedStages": 0,
          "numSkippedStages": 0,
          "numFailedStages": 1,
          "killedTasksSummary": {
           "Stage cancelled": 7
          }
         }
        ],
        "limit": 20,
        "rule": "ALL_DESC"
       },
       "parent_msg_id": "debc9a91-b3fe-4495-8c0f-fe15f8150595"
      },
      "text/plain": "StatementMeta(, bb9d753a-0434-4290-b0d5-543c1c0f738c, 5, Finished, Cancelled)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "execution_count": 3,
   "metadata": {},
   "id": "914a71f1-4dfa-4d77-af5a-f00ae6b51831"
  }
 ]
}
